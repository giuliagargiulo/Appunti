---
author: Giulia Gargiulo
---

Come abbiamo visto precedentemente, per l'esecuzione di un processo, le istruzioni da eseguire devono trovarsi in memoria fisica. 

Il modo più semplice, ma anche quello meno efficiente, per soddisfare questo requisito è **caricare l'intero spazio d'indirizzi logici del processo in memoria fisica**.
In questo modo però, le dimensioni dei programmi sono dipendenti dalle dimensioni della memoria fisica e l'implementazione da parte dei programmatori è più difficile.

In molti casi però, **non è necessario caricare l'intero programma in memoria**, infatti è possibile che non serva tutto in una volta. 

La possibilità di eseguire un programma che non si trova completamente in memoria è molto vantaggiosa:
1. Le dimensioni del programma non sono limitate alla quantità di memoria fisica disponibile. Gli utenti possono scrivere programmi per uno spazio di indirizzi virtuali molto più grande, semplificando la programmazione.
2. Poichè ogni processo utilizza meno memoria fisica, si possono eseguire più programmi contemporaneamente, ottenendo un aumento della produttività della CPU.
3. Per caricare o scaricare i programmi utente sono necessarie meno operazioni di I/O.

La memoria virtuale, quindi, si fonda sulla separazione percepita dall'utente della memoria logica dalla memoria fisica. Questa separazione permette di avere una memoria virtuale molto ampia, anche se la memoria fisica è più piccola.

Dal punto di vista logico, un processo inizia in corrispondenza di un certo indirizzo logico, e si estende alla memoria contigua come nella figura successiva.
La memoria fisica può essere organizzata sia in modo contiguo, sia utilizzando il paging, in quest'ultimo caso sarà compito del MMU associare le pagine logiche alle pagine fisiche. 
![[Screenshot 2024-11-11 alle 10.55.40.png|130]]
Allo heap viene lasciato lo spazio sufficiente per crescere verso l'alto poiché esso contiene la memoria allocata dinamicamente, stessa cosa per lo stack, che può crescere verso il basso, a causa delle ripetute chiamate a funzione. Lo spazio vuoto richiede pagine fisiche realmente esistenti solo nel caso in cui lo heap e lo stack crescano.  

>[!Important]
>Oltre alla divisione tra la memoria fisica e logica, la memoria virtuale offre il vantaggio a due o più processi di poter condividere i file e la memoria, mediante la **condivisione delle pagine**. I principali vantaggi sono:
>- Le librerie di sistema sono condivisibili da diversi processi.
>- Rende due o più processi in grado di condividere aree di memoria.
>- Consente che le pagine siano condivise durante la creazione di un processo (tramite una chiamata a `fork()`).

---
## Paginazione su richiesta (demand paging)
Un modo per gestire il caricamento in memoria di un programma residente su un disco consiste nel **caricare le pagine solo quando servono realmente**; questo metodo è detto **paginazione su richiesta**, ed è comunemente adottato dai sistemi con memoria virtuale. Esso è molto simile ad un sistema paginato con swapping dei processi, però invece dei processi vengono scambiate le pagine.

Le pagine sono caricate in memoria solo quando sono richieste durante l'esecuzione del programma, quindi una pagina a cui non si accede mai non viene mai caricata in memoria fisica.

La componente che si occupa della sostituzione delle pagine è detta **paginatore**.
Quando un processo sta per essere caricato in memoria, il paginatore ipotizza quali pagine verranno usate, e le carica in memoria (invece di caricare tutto il processo).

Per distinguere le pagine caricate in memoria da quelle presenti sui dischi si utilizza il **bit di validità**; se il bit è impostato a "valido" significa che la pagina corrispondente si trova in memoria, mentre se il bit è impostato come "invalido" significa che la pagina non appartiene allo spazio d'indirizzi logici del processo, oppure è valida ma attualmente si trova nel disco (in questo caso la tabella delle pagine contiene l'indirizzo che consente di trovare la pagina nei dischi).

>[!Warning]
>Per realizzare la paginazione su richiesta è necessario risolvere due problemi:
>1. Occorre decidere quanti frame assegnare ad ogni processo, tramite **un algoritmo di allocazione dei frame**.
>2. Quando è richiesta una sostituzione di pagina, bisogna decidere quale pagina sostituire, tramite **un algoritmo di sostituzione di pagina**.

### Gestione di un page fault
Se il processo tenta di accedere ad una pagina che non è stata caricata in memoria, avviene un **page fault trap** (eccezione di **assenza di pagina**).

L'architettura di gestione delle pagine nota che il bit nella tabella delle pagine è **invalido**, quindi invia un segnale di eccezione al SO per gestire il page fault nel seguente modo:
1. Si controlla la tabella interna del processo per capire se il riferimento fosse un accesso alla memoria valido o invalido.
2. Se il riferimento era invalido si termina il processo, altrimenti bisogna caricare la pagina corrispondente in memoria.
3. Si individua un frame libero e si carica la nuova pagina nel frame appena selezionato.
4. Quando la lettura dal disco è completata, si modificano la tabella delle pagine  e la tabella interna del processo per indicare che la pagina si trova attualmente in memoria.
5. Si riavvia l'istruzione interrotta dal segnale di eccezione. A questo punto il processo può accedere alla pagina.

>[!Important]
>E' possibile avviare l'esecuzione di un processo anche senza pagine in memoria!
>Il processo subirà un page fault, e dopo di che continuerà con l'esecuzione, subendo page fault finchè tutte le pagine necessarie non saranno caricate in memoria. In questo caso si parla di **paginazione su richiesta pura**.

Uno dei requisiti cruciali della paginazione su richiesta è la possibilità di rieseguire una qualsiasi istruzione a seguito di un page fault, infatti dopo un page fault è necessario il **restart delle istruzioni**. Avendo salvato lo stato del processo interrotto, occorre riavviare il processo esattamente dallo stesso punto e con lo stesso stato.

### Prestazioni della paginazione su richiesta
Attualmente, nella maggior parte dei calcolatori, il tempo di accesso in memoria ($T_a$), varia da 10 a 200 nanosecondi. Finchè non si verificano assenze di pagine, il tempo d'accesso effettivo è uguale al tempo di accesso in memoria. Se si verifica un page fault, occorre prima leggere dal disco la pagina, e poi accedere alla parola desiderata.

Supponendo che $p$ sia la probabilità che si verifichi un page fault ($0 \leq p \leq 1$), il tempo 
Il tempo di accesso effettivo è dato dalla seguente formula:
$$EAT = (1-p) * T_a + p*t$$
dove:
- $p$ è la probabilità che si verifichi un page fault ($0 \leq p \leq 1$).
- $t$ è il tempo di gestione del page fault.
- $T_a$ è il tempo di accesso in memoria.

Quindi, il tempo di accesso effettivo è **direttamente proporzionale** alla frequenza dei page fault.

---
### Sostituzione delle pagine
Supponiamo che si abbiano a disposizione 40 frame e che si vogliano eseguire contemporaneamente 6 processi, ciascuno dei quali è formato da 10 pagine, di cui solo 5 sono effettivamente usate. Consideriamo il caso in cui ciascuno di questi processi, per un insieme particolare di dati, abbia improvvisamente bisogno di tutte le 10 pagine, quindi sarebbero necessari 60 frame, ma ne sono disponibili solo 40.

In questo caso si verifica la **sovrallocazione**, cioè durante l'esecuzione di un processo si verifica un page fault, ma non ci sono frame liberi in cui inserire le nuove pagine. In questo caso si applica la **sostituzione delle pagine**.

La sostituzione delle pagine si basa sul seguente criterio: **se nessun frame è libero, si può liberarne uno attualmente inutilizzato**. Un frame si libera scrivendo il suo contenuto nell'area di swapping e aggiornando la tabella delle pagine per indicare che quella pagina non si trova più in memoria. Invece, il frame liberato si può utilizzare per caricare la pagina richiesta. 

La procedura per la gestione di un page fault descritta precendentemente si può modificare com segue:
1. Si individua la locazione nel disco della pagina richiesta.
2. Si cerca un frame libero: se esiste lo si usa, altrimenti si utilizza un **algoritmo di sostituzione delle pagine** per scegliere un frame da liberare, si salva il frame scelto nel disco e si aggiornano le tabelle delle pagine e dei blocchi di memoria.
3. Si scrive la pagina richiesta nel frame liberato.
4. Si riavvia il processo utente dall'istruzione che ha causato l'eccezione.

Se non esiste nessun frame libero sono necessari due trasferimenti di pagina per ogni page fault, ma questo sovraccarico si può ridurre associando ad ogni pagina un bit di modifica, che indica se la pagina è stata modificata dopo essere stata letta dal disco; in caso negativo non c'è bisogno di salvarla sul disco, perchè è già presente.

### Algoritmi di sostituzione delle pagine
Esistono molti algoritmi di sostituzione delle pagine, generalmente si sceglie quello col minor **page fault rate** (frequenza di page fault). Per stabilire il numero di page fault occorre conoscere anche il numero di frame disponibili.
#### Algoritmo di sostituzione FIFO 
L'algoritmo FIFO associa ad ogni pagina l'istante di tempo in cui è stata caricata in memoria, e se si deve sostituire una pagina, **si sostituisce quella presente in memoria da più tempo**. Non è necessario registrare l'istante di tempo in cui si carica la pagina in memoria, infatti basta inserire tutte le pagine presenti in memoria in una coda FIFO.

Dati 3 frame e la seguente stringa di riferimenti alle pagine, con l'algoritmo FIFO si ottengono 15 page fault:

![[Screenshot 2024-11-12 alle 00.14.17.png|550]]

#### Algoritmo ottimale (OTP)
L'algoritmo ottimale è quello che presenta la minima frequenza di page fault, ma è molto difficile da realizzare poiché bisogna conoscere in anticipo la stringa dei riferimenti alle pagine. Si **sostituisce la pagina che non verrà usata per il periodo di tempo più lungo**.

Dati 3 frame e la stringa dell'esempio precedente, con l'algoritmo OTP si hanno 9 page fault:

![[Screenshot 2024-11-12 alle 00.20.05.png|550]]

#### Algoritmo LRU
L'algoritmo LRU è un'approssimazione dell'OTP, infatti associa ad ogni pagina l'istante di tempo in cui è stata utilizzata per l'ultima volta. Quando bisogna sostituire una pagina, **si sostituisce la pagina che non è stata usata per il periodo di tempo più lungo**. 

Dati 3 frame e la stringa dell'esempio precedente, con l'algoritmo LRU si hanno 12 page fault:

![[Screenshot 2024-11-12 alle 00.23.25.png|550]]

#### Algoritmo second chance
---
### Allocazione dei frame
 A questo punto, è necessario stabilire un criterio per l'allocazione della memoria libera ai diversi processi. Il caso più semplice è quando si ha un singolo processo utente; ad esempio consideriamo un sistema che disponga di 128 Kb di memoria, con pagine da 1 Kb e quindi 128 frame, di cui 35 sono riservati al SO. Restano liberi 93 frame, che si possono gestire in due modi:
 1. Quando il processo inizia l'esecuzione, si genera una sequenza di page fault; le prime 93 pagine vengono inserite nei frame liberi, e una volta esaurite, si applica un algoritmo di sostituzione di pagine.
 2. Si riservano sempre 3 frame liberi, in modo che quando si verifica un page fault sia sempre disponibile un frame libero.

L'allocazione dei frame è soggetta ad alcuni vincoli:
- Non si possono allocare più frame di quanti ne siano disponibili, ammenochè non ci sia condivisione di pagine.
- E' **necessario assegnare un numero minino di frame ad ogni processo**, poiché con il diminuire dei frame, aumenta il page fault rate, e di conseguenza diminuiscono le **prestazioni**. Inoltre è necessario garantire che quando a seguito di un page fault una qualsiasi istruzione viene riavviata, i frame disponibili devono essere sufficienti per contenere tutte le pagine a cui l'istruzione fa riferimento.

Il numero minimo di frame è definito dall'architettura, mentre il numero massimo è definito dalla quantità di memoria fisica disponibile.

### Algoritmi di allocazione dei frame
I principali algoritmi di allocazione dei frame sono due: **equal allocation** e **proportional allocation**. Per entrambi gli algoritmi, l'allocazione dei frame ad ogni processo può variare in base al livello di **multiprogrammazione**, infatti se tale livello aumenta, diminuisce il numero di frame di ogni processo.
#### Equal allocation
E' il modo più semplice per dividere $m$ frame tra $n$ processi, e consiste nell'applicare **ad ogni processo lo stesso numero di frame**. Ad ogni processo saranno quindi assegnati $m/n$ frame. Ad esempio, dati 93 frame e 5 processi, ad ogni processo saranno assegnati $93/5 = 18$ frame.
#### Proportional allocation
Questo metodo si basa sul fatto che processi diversi hanno bisogno di quantità di memoria diverse. La memoria disponibile si assegna a ciascun processo secondo la propria dimensione: si supponga che $s_i$ sia la dimensione della memoria virtuale per il processo $p_i$, allora si definisce la seguente quantità $S = \sum_i s_i$, cioè la sommatoria di tutta la memoria virtuale dei processi. Quindi sia il numero totale di frame è $m$, al processo $p_i$ verranno assegnati $a_i$ frame, dove: $$a_i \approx (s_i / S)* m$$
Si consideri un sistema con frame da 1 Kb, e due processi rispettivamente da 10 Kb e 127 Kb, con 62 frame liberi a disposizione. In questo caso la equal allocation sarebbe inutile, perche al primo processo servono al massimo 10 frame.
Utilizzando la proportional allocation si ottiene $a_1 = (10 /137) *62 \approx 4$, $a_2 = (127 /137) *62 \approx 57$, quindi vengono assegnati ai processi $p_1$ e $p_2$ rispettivamente 4 e 57 frame.


>[!Nota]
>Sia con l'allocazione uniforme che con l'allocazione proporzionale, un processo a priorità elevata verrà trattato esattamente come un processo a bassa priorità. Una soluzione potrebbe essere l'uso dell'allocazione proporzionale in cui il rapporto dei frame non dipende dalle dimensioni relative dei processi, ma dalla loro priorità (**priority allocation**).

---
#### Allocazione globale e locale
Nel caso in cui ci siano più processi in competizione per i frame, gli algoritmi di sostituzione delle pagine possono classificarsi in due categorie: **sostituzione globale** e  **sostituzione locale**. 
- La sostituzione globale permette che ogni processo scelga un frame per la sostituzione dall'insieme di tutti i frame, anche se quel frame è allocato ad un altro processo. Questo modo può essere utile per esempio per gestire **processi a priorità**.
- La sostituzione locale permette che ogni processo scelga un frame solo dal proprio insieme di frame; in questo caso il numero di frame associati ad ogni processo non cambia.

In generale, la sostituzione globale genera una maggiore produttività del sistema, e per questo è il metodo più usato.

---
### Allocazione non uniforme della memoria
Spesso in sistemi con processori multipli, un processore può accedere più rapidamente ad alcune regioni di memoria rispetto ad altre. I sistemi in cui i tempi di accesso alla memoria variano in modo significativo, detti **sistemi con accesso non uniforma alla memoria (NUMA)**, sono più lenti dei sistemi nei quali memoria e processori risiedono sulla stessa scheda madre.

Le decisioni su quali frame di pagina memorizzare e dove memorizzarli possono condizionare in modo significativo le prestazioni nei sistemi NUMA. L’obiettivo d è quello di allocare i frame di memoria “il più vicino possibile” al processore sul quale il processo è in esecuzione, dove per “vicino” si intende “con latenza minima”, ovvero, di solito, sulla stessa scheda della CPU.

---
### Trashing (paginazione degenere)

Se il numero dei frame allocati a un processo con priorità bassa diviene inferiore al numero minimo richiesto dall’architettura del calcolatore, occorre sospendere l’esecuzione del processo, liberando tutti i frame allocati. Anche se si può ridurre al valore minimo il numero dei frame allocati, esiste un certo  **numero di pagine in uso attivo**.

**Il trashing si verifica quando un processo è occupato per più tempo nella sostituzione delle pagine che in esecuzione**, poiché non ha frame a sufficienza per contenere tutte le pagine in uso attivo. Quindi il processo interessato inizia a sostituire pagine di cui in realtà ha bisogno in quel momento, creando una serie di page fault.
![[Screenshot 2024-11-12 alle 17.12.28.png|450]]
Il trashing causa parecchi **problemi di prestazioni**, poichè il SO vigila sull'utilizzo della CPU, infatti se è basso, aumenta il grado di multiprogrammazione; si avvia un nuovo processo, utilizzando un algoritmo di sostituzione globale, che sostituisce le pagine senza tener conto del processo al quale appartengono. Se i frame a disposizione non sono sufficienti per tutti i processi in esecuzione, si ha una serie di page fault. Lo sheduler della CPU rileva la riduzione dell'utilizzo della CPU, e aumenta il grado di multiprogrammazione, cercando di avviare un nuovo processo.
La paginazione è quindi degenerata, e farà crollare l'utilizzo della CPU.

Gli effetti di questa situazione si possono limitare usando un algoritmo di sostituzione locale, o algoritmo di sostituzione per priorità.

---
### Modello di località di un processo
Per evitare il verificarsi del trashing, occorre fornire ad un processo tutti i frame di cui necessita. Per conoscere quanti frame servano ad ogni processo si può utilizzare il **modello di località**.

La **località** di un processo è un insieme di pagine che sono utilizzate attivamente dal processo (contemporaneamente). Un processo, durante la sua esecuzione si sposta di località in località, e spesso alcune di queste sono sovrapponibili.

Ad esempio, se si invoca una funzione, essa definisce una nuova località, contenente istruzioni, variabili locali e un sottoinsieme di quelle globali; quando la procedura termina, il processo lascia questa località, poichè le variabili locali e le istruzioni non sono più utilizzate attivamente.

Il modello di località è alla base del caching, poiché se ci accessi ai dati fossero casuali, anzichè per località, il caching sarebbe inutile.

Supponendo di allocare ad un processo il numero di frame necessari per sistemare le sue località attuali, finchè tutte le pagine non saranno presenti in memoria si verificheranno pagefault per quelle località; a questo punto, finché le località non subiranno cambiamenti, non si verificheranno pagefault.
Se si allocano meno frame rispetto alla dimensione della località attuale, invece, la paginazione degenera, provocando il **trashing**, poichè non si possono tenere in memoria tutte le pagine che il processo sta utilizzando attivamente.

***Modello Working set***
Il modello working set è basato sull'ipotesi di località. Esso utilizza un parametro, delta ($\Delta$), per definire una working set window (finestra dell'insieme di lavoro).
L'idea consiste nell'esaminare i più recenti $\Delta$ riferimenti alle pagine; l'insieme delle $\Delta$ pagine più recenti costituisce il **working set**. 

Se una pagina è in uso attivo, allora sarà nel working set, altrimenti dopo $\Delta$ unità di tempo, uscirà dal working set. Quindi, **l'insieme di lavoro è un'approssimazione della località del programma.**

![[Screenshot 2024-11-03 alle 16.29.21.png|500]]
Ad esempio, in questa immagine, se $\Delta = 10$, allora all'istante $t_1$ l'insieme di lavoro è $WS(t_1)=\{1,2,5,6,7\}$, mentre all'istante $t_2$ è $WS(t_2)=\{3,4\}$.

La caratteristica più importante del **working set** è la sua **dimensione**. Calcolando la dimensione dell'insieme di lavoro $WS_i$ , per ogni processo $p_i$ , si può determinare la richiesta totale di frame $D = \sum_i(WS_i)$. Se la richiesta totale $D$, è maggiore del numero di frame liberi $m$ ($D > m$), allora si verifica il **trashing**, poiché alcuni processi non dispongono del numero necessario di frame.

### Frequenza di page fault
Un altro modo per verificare che il numero di frame di un processo sia sufficiente, e quindi prevenire la paginazione degenere, è **controllare la frequenza di page fault**.

Se la frequenza di page fault è molto alta, il processo necessita di più frame, mentre se è troppo bassa il processo potrebbe disporre di troppi frame. Si può fissare un limite inferiore e superiore per la frequenza desiderata dei page fault.
- Se la frequenza supera il limite superiore, bisogna allocare a quel processo un nuovo frame; 
- Se la frequenza supera il limite inferiore, si sottrae un frame a quel processo;
- Se la frequenza delle assenze di pagine aumenta e non ci sono frame disponibili, occorre selezionare un processo e sospenderlo.
![[Screenshot 2024-11-12 alle 17.11.34.png|450]]
---
### Allocazione di memoria nel kernel
---

