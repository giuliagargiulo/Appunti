Un **processo** è un programma in esecuzione. E' qualcosa di più del codice di un programma, infatti un processo comprende:
- L'**attività corrente**, rappresentata dal valore del **program counter** e dal contenuto dei **registri** della CPU.
- **Layout di memoria**, che a sua volta contiene:
	- una **sezione testo**, contenente il codice del programma.
	- una **sezione dati**, che contiene le **variabili globali**.
	- il proprio **stack**, contenente i dati temporanei (i parametri di un metodo, gli indirizzi di ritorno e le **variabili locali**).
	- uno **heap** (non sempre presente), cioè la memoria allocata dinamicamente durante l'esecuzione del processo.

La sezione testo e la sezione dati sono di dimensione fissa, mentre stack e heap sono variabili a runtime.

>[!warning]
>Un **programma** non è un processo, ma un'**entità passiva**, come il contenuto di un file memorizzato in un disco, mentre un **processo** è un'**entità attiva**, con un program counter e delle risorse associate.
> 
> Un programma diventa un processo quando il file eseguibile che lo contiene viene **caricato in memoria**.
>
>Ad uno stesso programma possono corrispondere diversi processi tutti con una proprio stack di esecuzione.

## Stato di un processo
Un processo, durante la sua esecuzione, è soggetto a cambiamenti di stato. Ogni processo può trovarsi in uno tra i seguenti stati:
- **new**: processo creato.
- **running**: un'unità di elaborazione esegue le istruzioni del programma.
- **waiting**: il processo attende che si verifichi quache evento, come un'operazione di I/O o la ricezione di un segnale.
- **ready**: il processo attende di essere assegnato ad un'unità di elaborazione.
- **terminated**: il processo ha terminato l'esecuzione.

![[Screenshot 2024-10-11 alle 14.47.38.png|500]]
Il sistema operativo mantiene una tabella dei processi. Ogni processo è rappresentato nel SO da un blocco di controllo di un processo (PCB o TCB).
Un TBC contiene: stato del processo, program counter, registri di CPU, informazioni sullo sheduling della CPU, sulla gestione della memoria, di contabilizzazione delle risorse e sullo stato dell'I/O.

## Thread
I moderni SO consentono ai processi di gestire l'esecuzione di più flussi di controllo, detti **thread,** e quindi di svolgere più di un compito alla volta. I processi possono diramarsi in più sottounità di esecuzione, avendo più program counter per un processo e multipli flussi di controllo (threads) che condividono tra loro identità a risorse, ma hanno diverso stato esecutivo. Questo sistema necessita di ulteriori informazioni da memorizzare nella PBC per i threads.

---
## Sheduling dei processi
L'obiettivo della multiprogrammazione consiste nell'eseguire contemporaneamente più processi, in modo da massimizzare l'utilizzo della CPU. In questo modo gli utenti possono interagire con i programmi mentre sono in esecuzione. Per raggiungere questi obiettivi, lo **sheduler dei processi** seleziona un processo da eseguire dall'insieme di quelli disponibili.

Lo sheduler dei processi mantiene una **coda di sheduling dei processi**, formata da:
- **Job queue**, tutti i processi del sistema
- **Ready queue**, i processi caricati in memoria centrale (ready)
- **Wait queue**,  processi in attesa (waiting)
- **Device queue**, processi che attendono la disponibilità di un dispositivo di I/O (ne esiste una per ogni dispositivo)

Lo sheduling dei processi può essere rappresentato graficamente tramite il **diagramma di accodamento**. Un nuovo processo in **coda ready** attende la CPU; una volta che la CPU sta servendo quel processo, possono avvenire diversi eventi (I/O, fine tempo, fork, wait), che possono portare il processo alla terminazione o al reinserimento nella coda ready. I cerchi rappresentano le risorse che servono le code, e le frecce indicano il flusso dei processi nel sistema.

![[Screenshot 2024-10-16 alle 14.06.59.png|500]]
Quando termina la sua esecuzione, un processo viene rimosso da tutte le code, viene rimosso il suo PBC e deallocate tutte le risorse.

### Sheduler
Il sistema operativo deve selezionare i processi dalle code di sheduling, utilizzando uno **sheduler**. Esistono due tipi di sheduler:
1. **Short-term sheduler** (o **CPU sheduler**), seleziona quale processo deve essere eseguito dalla CPU. E' invocato frequentememte (a distanza di pochi millisecondi), e per questo deve essere molto veloce.

2. **Long-term sheduler** (o **job sheduler**), seleziona quale processo deve essere portato nella coda ready. E' invocato meno frequentemente (a distanza di secondi o pochi minuti), e quindi può essere più lento. Inoltre controlla anche il grado di multiprogrammazione, cioè il numero di processi presenti in memoria.  I processi possono essere divisi in: 
	 - I/O bound process: spendono più tempo in operazioni di I/O che in computazione, e richiedono quindi brevi accessi in CPU.
	 - CPU bound process: spendono più tempo in computazione, richiedono pochi e lunghi accessi in CPU.
	
3. **Medium-term sheduler**, può essere aggiunto se il grado di multiprogrammazione deve decrescere (minor contesa per la CPU); esso toglie i processi dalla memoria, li archivia su un disco, e successivamente li riporta in memoria per continuare l'esecuzione (swapping).
### Context switch
In presenza di un'interruzione, il sistema deve **salvare il contesto del processo corrente (rappresentato in PBC)** per poterlo ripristinare quando il processo potrà tornare in esecuzione, e **caricare il contesto del nuovo processo da eseguire**, attraverso il **context switch**. 
Il tempo di context switch è un **overhead**, infatti comporta un calo delle prestazioni dovuto al fatto che durante lo switching in sistema non fa lavoro "utile", e dipende dall'hardware del calcolatore.

---
## Operazioni sui processi
Il sistema operativo deve offrire meccanismi per: creare e terminare processi, comunicazione tra processi, sincronizzazione tra processi, gestione di processi.

### Creazione di un processo
Durante la sua esecuzione, un processo, detto **padre**, può creare numerosi processi, detti **figli**, tramite una chiamata di sistema (`create_process()` oppure` fork()`). Ciascun figlio, può creare a sua volta nuovi processi, formando un albero di processi.
Ogni processo è identificato tramite un **identificatore di processo**, detto **pid**.

**Opzioni di condivisione risorse:**
1. Padre e figlio condividono le stesse risorse
2. Figlio condivide un sottoinsieme delle risorse del padre
3. Padre e figlio non condividono alcuna risorsa

**Opzioni di esecuzione:**
1. Padre e figlio vengono eseguiti in concorrenza
2. Padre aspetta che il figlio finisca

Nel sistema operativo UNIX, un nuovo processo si crea con una chiamata a `fork()`, ed ha una copia dello spazio di memoria degli indirizzi del padre, permettendo al padre di comunicare facilmente col figlio. Entrambi i processi continuano l'esecuzione all'istruzione successiva alla chiamata a `fork()`, con una differenza: **nel processo figlio la chiamata a** `fork()` **restituisce zero**, mentre **nel processo padre restituisce il pid del figlio (diverso da zero)**, permettendo di distinguere i processi.
![[Screenshot 2024-10-17 alle 09.58.31.png]]
Dopo una chiamata a `fork()`, solitamente uno dei due processi effettua una chiamata a `exec()`, che carica in memoria un file binario ed avvia la sua esecuzione. In questo modo i processi padre e figlio procedono in modo diverso. Il padre può anche generare altri figli oppure effettuare una chiamata a `wait()`, per aspettare la terminazione del figlio.

```c
#include <sys/types.h>
#include <stdio.h>
#include <unistd.h>

int main(){
	pid_t pid;
	pid =fork();
	
	if (pid < 0){
		fprintf(stderr, "Fork failed");
		return 1;
	}
	else if(pid == 0)     //child process
		execlp("/bin/ls", "ls", NULL);
	else{         //parent process
		wait(NULL);
		printf("child complete");
	}
	return 0;	
}
```

---
### Terminazione di un processo
Un processo termina quando finisce l'esecuzione della sua ultima istruzione ed effettua una chiamata di sistema `exit()`. A questo punto, in processo figlio può ritornare alcuni dati e il suo pid al processo padre, che li riceve attraverso la chiamata di sistema `wait()`; ad esempio in UNIX: `pid = wait(&status)`.
Dopo la terminazione, tutte le risorse del processo vengono deallocate dal SO.

Il padre può anche terminare l'esecuzione di un processo figlio tramite una chiamata ad `abort()`, per vari motivi come ad esempio:
1. il figlio ha allocato troppe risorse
2. il task del figlio non è più richiesto
3. il padre termina e non consente ad un figlio di continuare
Alcuni sistemi operativi non permettono ai figli di esistere se i padri hanno terminato, quindi se un processo termina, tutti i figli terminano (**cascading termination**), e la terminazione è gestita dal SO.

In Unix/Linux se non c'e un padre in waiting, il figlio diventa **zombie**; se invece il padre termina prima del figlio senza invocare wait(), il figlio è **orphan**, e in Unix, viene adottato dal processo **init**, che chiama continuamente wait per ottenere lo status. 

---
## Comunicazione tra processi
I processi eseguiti in concorrenza nel SO possono essere:
1. **indipendenti**, se non possono influire su altri processi o subirne l'effetto; questo tipo di processo non condivide dati.
2. **cooperanti**, se influenza o può essere influenzato da altri processi in esecuzione; questo tipo di processo condivide dati con gli altri processi. Vantaggi: **condivisione di dati**, **velocità computazionale**, **modularità**.

I **processi cooperanti** necessitano di un meccanismo di comunicazione, chiamato **interprocess communication (IPC)**. Esistono due modelli principali di IPC:
1. **Shared memory**, in cui si stabilisce una zona di memoria condivisa dai processi operanti, che possono comunicare leggendo e scrivendo in questa zona; questo metodo è più veloce e richiede l'intervento del kernel solo per allocare la memoria condivisa.
2. **Message passing**, in cui la comunicazione avviene tramite lo scambio di messaggi tra i processi cooperanti; con questo metodo si possono scambiare poche informazioni, e tutti gli scambi passano per il kernel.

  --- `Message passing` ------------ `Shared memory`---
![[Screenshot 2024-10-18 alle 00.02.27.png|400]]
### Sistemi shared memory
La comunicazione tra processi tramite una memoria condivisa richiede che i processi cooperanti allochino una zona di memoria condivisa, di solito residente nello spazio degli indirizzi del processo che la alloca, e gli altri processi dovranno aggiungerla al loro spazio degli indirizzi. I processi leggono e scrivono su questo spazio, che non è controllato da SO, e hanno la responsabilità di non scrivere nella stessa locazione di memoria contemporaneamente.

Viene introdotto quindi il problema del **produttore-consumatore**, che nel caso della memoria condivisa, viene risolto utilizzando un **buffer** in cui il produttore può produrre un'unità, e il consumatore può consumarne una. I due processi devono essere sincronizzati, in modo tale che il consumatore non tenti di accedere ad un'unità non ancora creata. Esistono due tipi di buffer:
- **Unbounded-buffer** (illimitato): non ci sono limiti alla dimensione del buffer; il consumatore attende se il buffer è vuoto.
- **Bounded-buffer**: dimensione fissata del buffer; il consumatore attende se il buffer è vuoto, il produttore attende se è pieno.

### Sistemi message passing
Lo scambio di messaggi permette a due processi di comunicare, anche se si trovano su macchine diverse, connesse da una rete. Lo scambio di messaggi prevede almeno due operazioni, **send(message)** e **receive(message).**
Inoltre, per comunicare, due processi hanno bisogno di un canale di comunicazione, realizzabile in vari modi:
- **Canale fisico:** memoria condivisa, bus hardware, rete.
- **Canale logico:** comunicazione diretta o indiretta, comunicazione sincrona o asincrona, buffering dei messaggi automatico o esplicito

Nella comunicazione diretta, ogni processo che intende comunicare deve nominare esplicitamente il ricevente o il trasmittente della comunicazione:
- `send(P, message)`, invia message al processo P.
- `receive(Q, message)`, riceve message dal processo Q.

In questo caso, il canale di comunicazione ha le seguenti caratteristiche:
- Il canale è stabilito esattamente tra due processi, che conoscono l'identità reciproca.
- Per ogni coppia c'è esattamente un canale, che può essere unidirezionale o bidirezionale.


....

### Comunicazione indiretta


### Buffering


## Comunicazione nei sistemi client-server
pipe, socket...

---
